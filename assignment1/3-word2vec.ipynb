{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://web.stanford.edu/class/cs224n/assignment1/assignment1_soln.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (a) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use row vector, then"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\hat y_o = p(o|c) = \\frac{exp(u_o v_c^T)}{\\sum_{w=1}^W exp(u_w v_c^T)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "U = \\begin{bmatrix}\n",
    "u_1 \\\\ \n",
    "u_2 \\\\ \n",
    "\\vdots \\\\ \n",
    "u_W \\\\\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose the dimensions of the volcabulary and $v_c$ are $W$ and $D$, and $\\theta$ be a $W$-dimension row vector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{\\partial J}{\\partial v_c} = \\frac{\\partial J}{\\partial \\hat y} \\frac{\\partial \\hat y}{\\partial \\theta} \\frac{\\partial \\theta}{\\partial v_c}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on question 2,\n",
    "\n",
    "$$\\frac{\\partial J}{\\partial \\hat y} \\frac{\\partial \\hat y}{\\partial \\theta}  = \\hat y - y$$\n",
    "\n",
    "which is of shape $1 \\times W$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the definition of skipgram model,\n",
    "\n",
    "$$\n",
    "\\theta = [u_1 v_c^T, \\cdots, u_0 v_c^T, \\cdots, u_W v_c^T]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\theta}{\\partial v_c} = U = \\begin{bmatrix}\n",
    "u_1 \\\\ \n",
    "u_2 \\\\ \n",
    "\\vdots \\\\ \n",
    "u_W \\\\\n",
    "\\end{bmatrix} = U\n",
    "$$\n",
    "\n",
    "which has a shape of $W\\times D$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So\n",
    "\n",
    "$$ \n",
    "\\frac{\\partial J}{\\partial v_c} = (\\hat y - y) U\n",
    "$$\n",
    "\n",
    "The shape transformation: $(1 \\times W) (W \\times D)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to (a),\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\theta}{\\partial u_i} = \\begin{bmatrix}\n",
    "- 0 - \\\\ \n",
    "\\vdots \\\\ \n",
    "v_c\\\\\n",
    "\\vdots \\\\ \n",
    "- 0- \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "The derivative matrix is zero everywhere but at row $i$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then,\n",
    "\n",
    "$$\n",
    "\\frac{\\partial J}{\\partial u_i} = (\\hat y - y)\\begin{bmatrix}\n",
    "- 0 - \\\\ \n",
    "\\vdots \\\\ \n",
    "v_c\\\\\n",
    "\\vdots \\\\ \n",
    "- 0- \\\\\n",
    "\\end{bmatrix} = (\\hat y - y)_i v_c\n",
    "$$\n",
    "\n",
    "which is shape $1 \\times D$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, $\\frac{\\partial J}{\\partial U}$ is just about stacking all $(\\hat y - y)_i v_c$ together to get a $W \\times D$ matrix,\n",
    "\n",
    "$$\n",
    "\\frac{\\partial J}{\\partial U} = \\begin{bmatrix}\n",
    "\\partial J / \\partial u_0 \\\\ \n",
    "\\vdots \\\\ \n",
    "\\partial J / \\partial u_W \\\\ \n",
    "\\end{bmatrix} = (\\hat y - y)^T v_c\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given\n",
    "$$\n",
    "J_{neg-sample}(o, v_c, U) =  - \\bigg(\\mathrm{log}(\\sigma(u_o^T v_c)) + \\sum_{k=1}^K \\mathrm{log}(\\sigma(-u_k^T v_c)) \\bigg)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then,\n",
    "\n",
    "\\begin{align*}\n",
    "\\frac{\\partial J}{\\partial v_c}\n",
    "&= - \\bigg(\\frac{1}{\\sigma(u_o^T v_c)} \\frac{\\partial \\sigma(u_o^T v_c)}{\\partial \\theta} \\frac{\\partial \\theta}{\\partial v_c} \n",
    "+ \\sum_{k=1}^K \\frac{1}{\\sigma(-u_k^T v_c)} \\frac{\\partial \\sigma(-u_k^T v_c)}{\\partial \\theta} \\frac{\\partial \\theta}{\\partial v_c}(-1)     \\bigg) \\\\\n",
    "&= -\\bigg(\\frac{1}{\\sigma(u_o^T v_c)} \\sigma(u_o^T v_c) (1 - \\sigma(u_o^T v_c)) u_o - \\sum_{k=1}^K \\frac{1}{\\sigma(-u_k^T v_c)} \\sigma(-u_k^T v_c) (1 - \\sigma(-u_k^T v_c)) u_k \\bigg) \\\\\n",
    "&= (\\sigma(u_o^T v_c) - 1)u_o - \\sum_{k=1}^K (\\sigma(-u_k^T v_c) - 1)u_k \\\\\n",
    "\\frac{\\partial J}{\\partial u_o}\n",
    "&= (\\sigma(u_o^T v_c) - 1)v_c \\\\\n",
    "\\frac{\\partial J}{\\partial u_k}\n",
    "&= -(\\sigma(-u_k^T v_c) - 1)v_c \\;\\;\\;\\; \\text{for all } k = 1, 2, 3, ..., K\n",
    "\\end{align*}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Negative sampling is much more efficient softmax-CE loss because it avoids calculating the sum of exponentials over the whole vocabulary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skip-gram\n",
    "\n",
    "Predict surrounding words given the center word."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "J_{skip-gram}(\\mathrm{word}_{c-m}, ... ,{c+m}) = \\sum_{-m \\le j \\le m, j \\ne 0} F(w_{c+j}, v_c)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "\\frac {\\partial J_{skip-gram}(\\mathrm{word}_{c-m}, ... ,{c+m})}{\\partial v_c} \n",
    "&= \\sum_{-m \\le j \\le m, j \\ne 0} \\frac{\\partial F(w_{c+j}, v_c)}{\\partial v_c} \\\\\n",
    "&= \\sum_{-m \\le j \\le m, j \\ne 0} (\\hat y - y) U \\\\\n",
    "\\frac {\\partial J_{skip-gram}(\\mathrm{word}_{c-m}, ... ,{c+m})}{\\partial U}\n",
    "&= \\sum_{-m \\le j \\le m, j \\ne 0} (\\hat y - y)^T v_c\n",
    " \\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CBOW (Continuous Bag of Words)\n",
    "\n",
    "Predict the center word given the surrounding words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given\n",
    "\n",
    "$$\n",
    "\\hat v = \\sum_{-m \\le j \\le m, j \\ne 0} v_{c+j}\n",
    "$$\n",
    "$$\n",
    "J_{CBOW}(\\mathrm{word}_{c-m, ..., c+m}) = F(w_c, \\hat v)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "\\frac {\\partial J_{CBOW}(\\mathrm{word}_{c-m}, ... ,{c+m})}{\\partial \\hat v} \n",
    "&= \\sum_{-m \\le j \\le m, j \\ne 0} \\frac{\\partial F(w_{c+j}, \\hat v)}{\\partial \\hat v} \\\\\n",
    "&= \\sum_{-m \\le j \\le m, j \\ne 0} (\\hat y - y) U \\\\\n",
    "\\frac {\\partial J_{CBOW}(\\mathrm{word}_{c-m}, ... ,{c+m})}{\\partial U}\n",
    "&= \\sum_{-m \\le j \\le m, j \\ne 0} (\\hat y - y)^T \\hat v\n",
    " \\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
